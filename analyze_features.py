import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


def analyze_extracted_features():
    """–ê–Ω–∞–ª–∏–∑ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    features_df = pd.read_csv('real_data_features.csv', index_col=0)

    print("üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ò–ó–í–õ–ï–ß–ï–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 50)

    print(f"–í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features_df.columns)}")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(features_df)}")

    # –ê–Ω–∞–ª–∏–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏
    null_analysis = features_df.isnull().sum()
    null_features = null_analysis[null_analysis > 0]

    if len(null_features) > 0:
        print(f"\n‚ùå –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏:")
        for feature, null_count in null_features.items():
            print(f"   {feature}: {null_count} –ø—Ä–æ–ø—É—Å–∫–æ–≤ ({null_count / len(features_df):.1%})")
    else:
        print(f"\n‚úÖ –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω—ã!")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    numeric_features = features_df.select_dtypes(include=[np.number])

    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ò–ó–ù–ê–ö–û–í:")
    stats_summary = numeric_features.agg(['mean', 'std', 'min', 'max']).T
    stats_summary['cv'] = stats_summary['std'] / stats_summary['mean']  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10 —Å–∞–º—ã—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    informative_features = stats_summary[stats_summary['std'] > 0].sort_values('cv', ascending=False)

    print(f"\nüéØ –¢–û–ü-10 —Å–∞–º—ã—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø–æ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏):")
    for feature, row in informative_features.head(10).iterrows():
        print(f"   {feature:25} mean={row['mean']:6.2f} std={row['std']:6.2f} cv={row['cv']:.2f}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    key_features = ['text_length', 'word_count', 'lexical_diversity', 'composite_quality_score']
    available_features = [f for f in key_features if f in numeric_features.columns]

    if available_features:
        plt.figure(figsize=(15, 10))

        for i, feature in enumerate(available_features, 1):
            plt.subplot(2, 2, i)
            plt.hist(numeric_features[feature].dropna(), bins=20, alpha=0.7, edgecolor='black')
            plt.title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature}')
            plt.xlabel(feature)
            plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')

        plt.tight_layout()
        plt.savefig('features_distribution.png', dpi=150, bbox_inches='tight')
        plt.show()
        print(f"\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ features_distribution.png")

    # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    if len(numeric_features.columns) > 5:
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-15 —Å–∞–º—ã—Ö –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
        top_features = informative_features.head(15).index.tolist()

        plt.figure(figsize=(12, 10))
        correlation_matrix = numeric_features[top_features].corr()

        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',
                    center=0, square=True, cbar_kws={"shrink": .8})
        plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç–æ–ø-15)')
        plt.tight_layout()
        plt.savefig('features_correlation.png', dpi=150, bbox_inches='tight')
        plt.show()
        print(f"üìà –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ features_correlation.png")

    # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è
    if 'composite_quality_score' in numeric_features.columns:
        print(f"\nüéØ –ê–ù–ê–õ–ò–ó –ö–û–ú–ü–û–ó–ò–¢–ù–û–ì–û –ü–û–ö–ê–ó–ê–¢–ï–õ–Ø –ö–ê–ß–ï–°–¢–í–ê:")
        quality_scores = numeric_features['composite_quality_score']
        print(f"   –°—Ä–µ–¥–Ω–µ–µ: {quality_scores.mean():.3f}")
        print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {quality_scores.std():.3f}")
        print(f"   –î–∏–∞–ø–∞–∑–æ–Ω: [{quality_scores.min():.3f}, {quality_scores.max():.3f}]")

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º
        quantiles = quality_scores.quantile([0.25, 0.5, 0.75])
        print(f"   –ö–≤–∞–Ω—Ç–∏–ª–∏: 25%={quantiles[0.25]:.3f}, 50%={quantiles[0.5]:.3f}, 75%={quantiles[0.75]:.3f}")


def check_feature_correlations_with_target():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏)"""

    features_df = pd.read_csv('real_data_features.csv', index_col=0)

    # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    score_columns = [col for col in features_df.columns if 'score' in col.lower() or '–æ—Ü–µ–Ω–∫' in col.lower()]

    if score_columns:
        target_col = score_columns[0]
        print(f"\nüéØ –ö–û–†–†–ï–õ–Ø–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í –° {target_col}:")
        print("-" * 40)

        correlations = features_df.corr()[target_col].abs().sort_values(ascending=False)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10 –Ω–∞–∏–±–æ–ª–µ–µ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        top_correlated = correlations.head(11)  # +1 –ø–æ—Ç–æ–º—É —á—Ç–æ target —Å–∞–º —Å —Å–æ–±–æ–π

        for feature, corr in top_correlated.items():
            if feature != target_col:
                actual_corr = features_df.corr()[target_col][feature]
                direction = "‚Üë" if actual_corr > 0 else "‚Üì"
                significance = "***" if abs(actual_corr) > 0.3 else "**" if abs(actual_corr) > 0.2 else "*" if abs(
                    actual_corr) > 0.1 else ""
                print(f"   {direction} {feature:25} {actual_corr:+.3f} {significance}")
    else:
        print(f"\n‚ÑπÔ∏è –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–æ—Ü–µ–Ω–∫–∏) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")


if __name__ == "__main__":
    analyze_extracted_features()
    check_feature_correlations_with_target()
