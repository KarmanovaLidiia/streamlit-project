import os
import json
import time
import zipfile
import threading
from pathlib import Path

import pandas as pd
import streamlit as st

from src.predict import pipeline_infer
from src.semantic_features import _load_model  # <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

# --------------------------- SAFE INIT ---------------------------
if not hasattr(st, "session_state"):
    st.session_state = {}

st.set_page_config(
    page_title="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞",
    layout="centered"
)

# --------------------------- UI / PAGE ---------------------------
st.title("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞")
st.caption("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∫–∞–∫ –≤ –∑–∞–¥–∞–Ω–∏–∏. –ù–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∏—Ç–µ —Ñ–∞–π–ª —Å –∫–æ–ª–æ–Ω–∫–æ–π `pred_score`.")

st.info(
    "‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (>10 –ú–ë) –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1‚Äì3 –º–∏–Ω—É—Ç—ã –∏–∑-–∑–∞ —Å–µ—Ç–∏. "
    "–ü–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞ –¥–æ–∂–¥–∏—Ç–µ—Å—å –ø–æ—è–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ."
)

with st.expander("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞", expanded=True):
    fast_mode = st.checkbox(
        "–ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–æ–Ω (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)", value=True,
        help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ N —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω."
    )
    row_limit = st.number_input(
        "–°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –≤–∑—è—Ç—å –≤ –±—ã—Å—Ç—Ä–æ–º —Ä–µ–∂–∏–º–µ", min_value=100, max_value=100_000,
        value=2000, step=100
    )
    st.caption(
        "–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º –Ω–µ –º–µ–Ω—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Äî "
        "–æ–Ω –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–µ—Ç —Å—ç–º–ø–ª –ø–µ—Ä–≤—ã—Ö N —Å—Ç—Ä–æ–∫."
    )

placeholder = st.empty()
uploaded = placeholder.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (–∏–ª–∏ ZIP —Å CSV –≤–Ω—É—Ç—Ä–∏)", type=["csv", "zip"])
if uploaded is not None:
    with st.spinner("üì¶ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è..."):
        time.sleep(1.0)
    size_mb = getattr(uploaded, "size", 0) / 1e6 if hasattr(uploaded, "size") else 0
    st.success(f"‚úÖ –§–∞–π–ª `{uploaded.name}` –∑–∞–≥—Ä—É–∂–µ–Ω ({size_mb:.1f} –ú–ë).")
    placeholder.empty()

run = st.button("–û—Ü–µ–Ω–∏—Ç—å", type="primary", disabled=uploaded is None)

# --------------------------- PATHS ---------------------------
TMP_DIR_IN = Path("data/raw")
TMP_DIR_OUT = Path("data/processed")
OUTPUTS_DIR = Path("data/outputs")
TMP_DIR_IN.mkdir(parents=True, exist_ok=True)
TMP_DIR_OUT.mkdir(parents=True, exist_ok=True)
OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)

TMP_IN = TMP_DIR_IN / "tmp_input.csv"
TMP_OUT = TMP_DIR_OUT / "tmp_output.csv"

PROGRESS_FILE = Path("/tmp/progress.json")
os.environ["PROGRESS_FILE"] = str(PROGRESS_FILE)

STAGE_WEIGHTS = {
    "–∑–∞–≥—Ä—É–∑–∫–∞ CSV": 2,
    "–æ—á–∏—Å—Ç–∫–∞": 6,
    "–±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏": 6,
    "—Å–µ–º–∞–Ω—Ç–∏–∫–∞": 55,
    "q4-—Ñ–∏—á–∏": 10,
    "on-topic": 2,
    "–∏–Ω—Ñ–µ—Ä–µ–Ω—Å CatBoost": 15,
    "–æ–±—ä—è—Å–Ω–µ–Ω–∏—è": 3,
    "—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ": 1,
    "–≥–æ—Ç–æ–≤–æ": 0,
}

def _save_bytes_to(tmp_path: Path, raw: bytes):
    tmp_path.parent.mkdir(parents=True, exist_ok=True)
    with open(tmp_path, "wb") as f:
        f.write(raw)

def _read_any_csv(path: Path, nrows: int | None = None) -> pd.DataFrame:
    try:
        return pd.read_csv(path, nrows=nrows, encoding="utf-8-sig", sep=None, engine="python")
    except Exception:
        return pd.read_csv(path, nrows=nrows, encoding="utf-8", sep=None, engine="python")

def _write_csv(df: pd.DataFrame, path: Path):
    df.to_csv(path, index=False, encoding="utf-8-sig")

def _calc_total_progress(cur_stage: str, current: int, total: int) -> float:
    stages = list(STAGE_WEIGHTS.keys())
    total_weight = sum(STAGE_WEIGHTS.values()) or 100.0
    done_weight = 0.0
    for s in stages:
        if s == cur_stage:
            break
        done_weight += STAGE_WEIGHTS.get(s, 0)
    stage_weight = STAGE_WEIGHTS.get(cur_stage, 0)
    frac = min(max(current / float(total), 0.0), 1.0) if total else 0.0
    return (done_weight + stage_weight * frac) / total_weight

def _read_progress():
    try:
        if PROGRESS_FILE.exists():
            with open(PROGRESS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {"stage": "–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞", "current": 0, "total": 1, "note": ""}

def _extract_zip_first_csv_to(dest_csv_path: Path, uploaded_file) -> bool:
    if not uploaded_file.name.lower().endswith(".zip"):
        return False
    try:
        with zipfile.ZipFile(uploaded_file) as zf:
            csv_name = next((n for n in zf.namelist() if n.lower().endswith(".csv")), None)
            if not csv_name:
                st.error("–í ZIP –Ω–µ –Ω–∞–π–¥–µ–Ω CSV-—Ñ–∞–π–ª.")
                st.stop()
            with zf.open(csv_name) as src, open(dest_csv_path, "wb") as dst:
                dst.write(src.read())
        return True
    except zipfile.BadZipFile:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å ZIP-—Ñ–∞–π–ª (–ø–æ–≤—Ä–µ–∂–¥—ë–Ω?).")
        st.stop()
    return False

def _list_outputs(max_items: int = 10):
    files = sorted(OUTPUTS_DIR.glob("predicted-*.csv"), key=lambda p: p.stat().st_mtime, reverse=True)
    return files[:max_items]

# --------------------------- MAIN ---------------------------
if uploaded and run:
    start_time = time.time()
    try:
        if PROGRESS_FILE.exists():
            PROGRESS_FILE.unlink(missing_ok=True)
    except Exception:
        pass

    with st.status("‚è≥ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∑–∞–ø—É—Å–∫—É...", expanded=True) as status:
        st.write("–°–æ—Ö—Ä–∞–Ω—è—é –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é —Ñ–∞–π–ª‚Ä¶")

        handled_zip = _extract_zip_first_csv_to(TMP_IN, uploaded)
        if handled_zip:
            st.info(f"üì¶ ZIP —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω, –Ω–∞–π–¥–µ–Ω CSV ‚Üí `{TMP_IN.name}`.")
        else:
            raw_bytes = uploaded.read()
            _save_bytes_to(TMP_IN, raw_bytes)

        if fast_mode and not handled_zip:
            st.write(f"–ß–∏—Ç–∞—é –ø–µ—Ä–≤—ã–µ {row_limit} —Å—Ç—Ä–æ–∫ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞‚Ä¶")
            try:
                df_head = _read_any_csv(TMP_IN, nrows=int(row_limit))
                _write_csv(df_head, TMP_IN)
                st.success(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Å—ç–º–ø–ª –∏–∑ {len(df_head):,} —Å—Ç—Ä–æ–∫.")
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –±—ã—Å—Ç—Ä—ã–π —Å—ç–º–ø–ª: {e}. –ü–æ–π–¥—É –ø–æ –ø–æ–ª–Ω–æ–º—É —Ñ–∞–π–ª—É.")

        if fast_mode:
            os.environ["FAST_ROW_LIMIT"] = str(int(row_limit))
            os.environ["DISABLE_EXPLANATIONS"] = "1"
        else:
            os.environ.pop("FAST_ROW_LIMIT", None)
            os.environ.pop("DISABLE_EXPLANATIONS", None)
        os.environ["CHUNK_SIZE"] = "500"
        os.environ["PROGRESS_FILE"] = str(PROGRESS_FILE)

        # üî• –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º –º–æ–¥–µ–ª—å SentenceTransformer –∑–∞—Ä–∞–Ω–µ–µ
        try:
            _ = _load_model()
            st.write("‚úÖ –ú–æ–¥–µ–ª—å SentenceTransformer –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø—Ä–æ–≥—Ä–µ—Ç–∞.")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∑–∞—Ä–∞–Ω–µ–µ: {e}")

        status.update(label="üöÄ –ó–∞–ø—É—Å–∫–∞—é –∏–Ω—Ñ–µ—Ä–µ–Ω—Å‚Ä¶")

    err_box = st.empty()
    prog_bar = st.progress(0, text="–°—Ç–∞—Ä—Ç...")
    stage_text = st.empty()

    def _worker():
        try:
            pipeline_infer(TMP_IN, TMP_OUT)
        except Exception as e:
            try:
                with open(PROGRESS_FILE, "w", encoding="utf-8") as f:
                    json.dump({"stage": "error", "current": 0, "total": 1, "note": str(e)}, f)
            except Exception:
                pass

    t = threading.Thread(target=_worker, daemon=True)
    t.start()

    while t.is_alive():
        info = _read_progress()
        if info.get("stage") == "error":
            err_box.error(f"–í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {info.get('note')}")
            st.stop()

        stage = info.get("stage", "—Ä–∞–±–æ—Ç–∞")
        cur = int(info.get("current", 0))
        tot = max(int(info.get("total", 1)), 1)
        note = info.get("note", "")

        frac = _calc_total_progress(stage, cur, tot)
        prog_bar.progress(int(frac * 100), text=f"{stage} ‚Ä¢ {cur}/{tot} {note}")
        stage_text.write(f"–¢–µ–∫—É—â–∞—è —Å—Ç–∞–¥–∏—è: **{stage}** &nbsp;&nbsp; {cur}/{tot} {note}")
        time.sleep(0.6)

    info = _read_progress()
    if info.get("stage") == "error":
        err_box.error(f"–í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {info.get('note')}")
        st.stop()
    prog_bar.progress(100, text="–ì–æ—Ç–æ–≤–æ ‚úÖ")

    duration = int(time.time() - start_time)
    try:
        df_res = _read_any_csv(TMP_OUT)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç `{TMP_OUT}`: {e}")
        st.stop()

    ts = time.strftime("%Y%m%d-%H%M%S")
    saved_path = OUTPUTS_DIR / f"predicted-{ts}.csv"
    saved_path.write_bytes(TMP_OUT.read_bytes())

    st.success(f"–ì–æ—Ç–æ–≤–æ –∑–∞ {duration} —Å–µ–∫. –ù–∏–∂–µ –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
    st.dataframe(df_res.head(20), use_container_width=True)

    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
        data=saved_path.read_bytes(),
        file_name=saved_path.name,
        mime="text/csv",
        type="primary"
    )

    with st.expander("üóÇ –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ)"):
        files = _list_outputs()
        if not files:
            st.caption("–ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
        else:
            for f in files:
                cols = st.columns([3, 1])
                cols[0].markdown(
                    f"**{f.name}** ‚Äî {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(f.stat().st_mtime))} ¬∑ {(f.stat().st_size/1024):.1f} KB"
                )
                cols[1].download_button(
                    "–°–∫–∞—á–∞—Ç—å", data=f.read_bytes(), file_name=f.name, mime="text/csv", key=f"dl_{f.name}"
                )

    with st.expander("‚ÑπÔ∏è –ü–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ —É—Å–∫–æ—Ä–µ–Ω–∏—é"):
        st.markdown(
            "- –î–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ **–±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–æ–Ω** ‚Äî –±—ã—Å—Ç—Ä–µ–µ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç.\n"
            "- –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö CSV –º–æ–∂–µ—Ç –∑–∞–Ω–∏–º–∞—Ç—å –≤—Ä–µ–º—è –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º –∂–µ–ª–µ–∑–µ.\n"
            "- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –µ—â—ë –±—ã—Å—Ç—Ä–µ–µ: –∑–∞—Ä–∞–Ω–µ–µ –Ω–∞—Ä–µ–∂—å—Ç–µ –≤—Ö–æ–¥–Ω–æ–π CSV –Ω–∞ —á–∞—Å—Ç–∏ –∏ –ø—Ä–æ–≥–æ–Ω—è–π—Ç–µ –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ."
        )
